"""
Exemplo avan√ßado: Treinamento do modelo com dados sint√©ticos
"""
import sys
from pathlib import Path

# Adicionar o diret√≥rio raiz ao PYTHONPATH
root_dir = Path(__file__).parent.parent
sys.path.insert(0, str(root_dir))

import numpy as np
from datetime import datetime, timedelta
import random

from src.models.test_case import ExecutionFeedback
from src.recommender.ml_recommender import MLTestRecommender
from src.utils.data_generator import SyntheticDataGenerator


def simulate_execution(
    test_order: list,
    recommender: MLTestRecommender,
    follow_recommendation_rate: float = 0.8
) -> list:
    """
    Simula execu√ß√£o de testes e gera feedback
    
    Args:
        test_order: Ordem dos testes
        recommender: Recomendador
        follow_recommendation_rate: Taxa de seguir recomenda√ß√£o
        
    Returns:
        Lista de feedbacks
    """
    feedbacks = []
    
    for i, test in enumerate(test_order):
        # Simular tempo de execu√ß√£o (com varia√ß√£o)
        base_time = test.get_total_estimated_time()
        actual_time = base_time * random.uniform(0.8, 1.3)
        
        # Simular sucesso (baseado na success_rate do teste)
        success = random.random() < test.success_rate
        
        # Simular se seguiu recomenda√ß√£o
        followed = random.random() < follow_recommendation_rate
        
        # Simular rating (melhor para testes r√°pidos e bem-sucedidos)
        if success and actual_time < base_time:
            rating = random.randint(4, 5)
        elif success:
            rating = random.randint(3, 5)
        else:
            rating = random.randint(1, 3)
        
        # Simular necessidade de reset (raro se ordem for boa)
        required_reset = False
        if i > 0:
            prev_test = test_order[i-1]
            # Reset se teste anterior foi destrutivo e atual precisa de estado limpo
            if (prev_test.has_destructive_actions() and 
                not test.has_destructive_actions() and
                random.random() < 0.1):
                required_reset = True
                rating = max(1, rating - 2)  # Penalizar rating
        
        feedback = ExecutionFeedback(
            test_case_id=test.id,
            executed_at=datetime.now() + timedelta(seconds=sum(
                t.get_total_estimated_time() for t in test_order[:i]
            )),
            actual_execution_time=actual_time,
            success=success,
            followed_recommendation=followed,
            tester_rating=rating,
            required_reset=required_reset,
            notes=f"Execu√ß√£o {'bem-sucedida' if success else 'falhou'}"
        )
        
        feedbacks.append(feedback)
    
    return feedbacks


def main():
    """Fun√ß√£o principal de treinamento avan√ßado"""
    print("=" * 80)
    print("TREINAMENTO AVAN√áADO DO MODELO DE RECOMENDA√á√ÉO")
    print("=" * 80)
    print()
    
    # Configura√ß√£o
    NUM_TRAINING_SUITES = 10
    TESTS_PER_SUITE = 15
    
    print("‚öôÔ∏è  Configura√ß√£o:")
    print(f"  - Su√≠tes de treinamento: {NUM_TRAINING_SUITES}")
    print(f"  - Testes por su√≠te: {TESTS_PER_SUITE}")
    print()
    
    # Gerar dados sint√©ticos
    print("üîÑ Gerando dados sint√©ticos...")
    generator = SyntheticDataGenerator(seed=42)
    training_suites = generator.generate_multiple_suites(
        num_suites=NUM_TRAINING_SUITES,
        tests_per_suite=TESTS_PER_SUITE
    )
    print(f"‚úì Geradas {len(training_suites)} su√≠tes de teste")
    print()
    
    # Criar e treinar recomendador
    print("ü§ñ Inicializando recomendador...")
    recommender = MLTestRecommender(model_type='random_forest')
    print("‚úì Recomendador inicializado")
    print()
    
    # Simular m√∫ltiplas sess√µes de teste
    print("üìä Simulando sess√µes de teste e coletando feedback...")
    print()
    
    total_feedbacks = 0
    
    for suite_idx, suite in enumerate(training_suites, 1):
        print(f"Su√≠te {suite_idx}/{NUM_TRAINING_SUITES}: {suite.name}")
        
        # Obter recomenda√ß√£o
        recommendation = recommender.recommend_order(suite.test_cases)
        
        # Organizar testes na ordem recomendada
        test_order = [
            tc for tc in suite.test_cases 
            if tc.id in recommendation.recommended_order
        ]
        
        # Simular execu√ß√£o e coletar feedback
        feedbacks = simulate_execution(test_order, recommender)
        
        # Adicionar feedbacks ao modelo
        for feedback in feedbacks:
            recommender.add_feedback(feedback, test_order)
            total_feedbacks += 1
        
        # Estat√≠sticas da execu√ß√£o
        avg_rating = np.mean([f.tester_rating for f in feedbacks if f.tester_rating])
        num_resets = sum(1 for f in feedbacks if f.required_reset)
        success_rate = sum(1 for f in feedbacks if f.success) / len(feedbacks)
        
        print(f"  ‚îú‚îÄ Feedbacks coletados: {len(feedbacks)}")
        print(f"  ‚îú‚îÄ Rating m√©dio: {avg_rating:.2f}/5")
        print(f"  ‚îú‚îÄ Resets necess√°rios: {num_resets}")
        print(f"  ‚îî‚îÄ Taxa de sucesso: {success_rate:.1%}")
        print()
    
    print(f"‚úì Total de feedbacks coletados: {total_feedbacks}")
    print()
    
    # Treinar modelo final
    print("üéì Treinando modelo com todos os dados...")
    recommender.train()
    print()
    
    # Avaliar modelo em nova su√≠te
    print("üß™ Avaliando modelo em su√≠te de teste...")
    generator_test = SyntheticDataGenerator(seed=999)
    test_suite = generator_test.generate_test_suite(num_tests=20)
    
    # Comparar recomenda√ß√£o do modelo vs. heur√≠stica
    print("\nüìä Compara√ß√£o: Modelo Treinado vs. Heur√≠stica")
    print("-" * 80)
    
    # Recomenda√ß√£o do modelo treinado
    rec_ml = recommender.recommend_order(test_suite.test_cases, use_heuristics=False)
    print(f"\nü§ñ Modelo ML:")
    print(f"  - Confian√ßa: {rec_ml.confidence_score:.1%}")
    print(f"  - Tempo estimado: {rec_ml.estimated_total_time:.1f}s")
    print(f"  - Resets estimados: {rec_ml.estimated_resets}")
    
    # Recomenda√ß√£o heur√≠stica
    rec_heur = recommender.recommend_order(test_suite.test_cases, use_heuristics=True)
    print(f"\nüìê Heur√≠stica:")
    print(f"  - Confian√ßa: {rec_heur.confidence_score:.1%}")
    print(f"  - Tempo estimado: {rec_heur.estimated_total_time:.1f}s")
    print(f"  - Resets estimados: {rec_heur.estimated_resets}")
    
    # Calcular melhorias
    time_improvement = (
        (rec_heur.estimated_total_time - rec_ml.estimated_total_time) / 
        rec_heur.estimated_total_time * 100
    )
    reset_reduction = rec_heur.estimated_resets - rec_ml.estimated_resets
    
    print(f"\nüìà Melhorias do Modelo:")
    print(f"  - Redu√ß√£o de tempo: {time_improvement:+.1f}%")
    print(f"  - Redu√ß√£o de resets: {reset_reduction:+d}")
    print()
    
    # Salvar modelo treinado
    print("üíæ Salvando modelo treinado...")
    recommender.save_model("models/trained_recommender.pkl")
    print("‚úì Modelo salvo: models/trained_recommender.pkl")
    print()
    
    # Resumo final
    print("=" * 80)
    print("‚úÖ TREINAMENTO CONCLU√çDO COM SUCESSO!")
    print("=" * 80)
    print()
    print("üìä Resumo:")
    print(f"  - Total de su√≠tes processadas: {NUM_TRAINING_SUITES}")
    print(f"  - Total de feedbacks: {total_feedbacks}")
    print(f"  - Modelo est√° treinado: {recommender.is_trained}")
    print(f"  - Amostras de treinamento: {len(recommender.training_data['y'])}")
    print()
    print("üöÄ Pr√≥ximos passos:")
    print("  1. Use o modelo treinado em suas su√≠tes reais")
    print("  2. Continue fornecendo feedback para melhorar")
    print("  3. Monitore as m√©tricas de desempenho")
    print()


if __name__ == "__main__":
    main()
